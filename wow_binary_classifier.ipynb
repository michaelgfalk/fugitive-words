{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wow_binary_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michaelgfalk/fugitive-words/blob/master/wow_binary_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "up5o6_-Inva1"
      },
      "source": [
        "# Introduction: Version 2 of foreign word detection model\n",
        "\n",
        "Initial experiments with the more general language modelling approach yielded less than satisfactory results. At best, the model seemed to be able to achieve 50% precision with 75% recall when used to discriminate Aboriginal from English words.\n",
        "\n",
        "This notebook tries a different approach: what if the problem were seen as a binary classification problem, rather than as a language modelling task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxVeDcGksyU5"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Dense, Concatenate, LSTM, CuDNNLSTM, Dropout\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer # For one-hot encoding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive # For saving\n",
        "import pickle as p\n",
        "import regex as re\n",
        "import pandas as pd\n",
        "\n",
        "# Create custom metrics (needed to load/compile model)\n",
        "def prec(y_true, y_pred):\n",
        "  t_one = K.greater_equal(y_true, 0.5) # Which words are actually Aboriginal?\n",
        "  p_one = K.greater_equal(y_pred, 0.5) # Which did the model predict were Aboriginal?\n",
        "  true_pos = K.all(K.concatenate([t_one, p_one], axis = 1), axis = 1) # Which predictions were correct?\n",
        "  \n",
        "  # Cast to float\n",
        "  true_pos = K.cast(true_pos, 'float16')\n",
        "  p_one = K.cast(p_one, 'float16')\n",
        "  \n",
        "  return K.sum(true_pos) / K.sum(p_one)\n",
        "\n",
        "def rec(y_true, y_pred):\n",
        "  t_one = K.greater_equal(y_true, 0.5) # Which words are actually Aboriginal?\n",
        "  p_one = K.greater_equal(y_pred, 0.5) # Which did the model predict were Aboriginal?\n",
        "  true_pos = K.all(K.concatenate([t_one, p_one], axis = 1), axis = 1) # Correct predictions of Aboriginal words\n",
        "  \n",
        "  # Cast to float\n",
        "  true_pos = K.cast(true_pos, 'float16')\n",
        "  t_one = K.cast(t_one, 'float16')\n",
        "  \n",
        "  return K.sum(true_pos) / K.sum(t_one)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-Ny4zgYHTLI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "a5c72ba4-e940-4b2b-cea3-e62b7227dbad"
      },
      "source": [
        "# Link to Google drive for disk access\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjY9UAbzy0qP"
      },
      "source": [
        "# set random seed for notebook\n",
        "random_seed = 691"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSEiD0mz8I9U"
      },
      "source": [
        "# 1. Import and clean training data\n",
        "\n",
        "For this task, we will use a different training/test set than before. Now we will use both English and Aboriginal words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRxEbpy9VZsi"
      },
      "source": [
        "def clean_text(data_frame):\n",
        "  \"\"\"Cleans the text of a data_frame, assuming it has a 'word' column.\"\"\"\n",
        "  # Drop rows with a comma or space in the word colume\n",
        "  # This should remove all of the English and phrases that creep into the 'word' column\n",
        "  filt = ~data_frame.word.str.contains(r',|\\s', na = True, regex = True)\n",
        "  data_frame = data_frame.loc[filt].reset_index(drop = True) # Need to rest index to avoid 'chained assignment' problem\n",
        "  \n",
        "  # Peform string operations\n",
        "  data_frame.loc[:,'word'] = (data_frame['word']\n",
        "                  .str.replace(r'&.{1,7};', '') # Strip out html entities\n",
        "                  .str.replace(r'\\\\N', '') # Strip out missing values written as '\\N'\n",
        "                  .str.replace(r'\\(.+\\)', '') # Strip out parenthetical comments\n",
        "                  .str.normalize('NFKD') # Strip out accents\n",
        "                  .str.encode('ascii', errors='ignore')\n",
        "                  .str.decode('utf-8') \n",
        "                  .str.replace(r'\\d|\\W|_', '') # Strip out all non-word characters and underscores\n",
        "                  .str.lower() # To lower case\n",
        "                 )\n",
        "\n",
        "  # Only keep rows with three or more characters in the OriginalForm\n",
        "  data_frame = data_frame.loc[data_frame.word.str.len() >= 3].reset_index(drop = True)\n",
        "  \n",
        "  return data_frame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IAT8hgI1AdU"
      },
      "source": [
        "## 1.1 Import Aboriginal Corpora"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3spkhgl29Wl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "427ec71f-0142-4372-a915-0ce9540ee21d"
      },
      "source": [
        "# Import chirila csv\n",
        "with open('/content/gdrive/My Drive/waves_of_words/chirila_data.csv') as f:\n",
        "  chirila_df = pd.read_csv(f)\n",
        "  \n",
        "chirila_df.columns = ['id', 'lang', 'word', 'row_number']\n",
        "\n",
        "print(f'There are {len(chirila_df)} words in the chirila dataset.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 229090 words in the chirila dataset.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6s8uwfmx85BW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e06b2cc5-24a0-497d-b791-acf39f911700"
      },
      "source": [
        "# First filter out the silly results:\n",
        "\n",
        "# Drop rows with an NaN\n",
        "chirila_df.dropna(thresh = 3, inplace = True)\n",
        "\n",
        "chirila_df = clean_text(chirila_df)\n",
        "\n",
        "# Sanity check\n",
        "print(f'After preprocessing, there are {len(chirila_df)} training examples in chirila_df.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After preprocessing, there are 191091 training examples in chirila_df.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2dtlx4u09TW"
      },
      "source": [
        "## 1.2 Import English corpora"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td2wqkpNntO2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "577f111c-4125-4bf0-abb9-5317ad46ce09"
      },
      "source": [
        "# Get training data from NLTK\n",
        "import nltk\n",
        "nltk.download('brown')\n",
        "nltk.download('reuters')\n",
        "nltk.download('gutenberg')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8Vc6udBdv2O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e0690bb1-feb0-4408-ea56-7898ac63c4f4"
      },
      "source": [
        "# Get training data from BYU corpora samples\n",
        "byu_words = []\n",
        "with open('/content/gdrive/My Drive/waves_of_words/byu_lexicons.txt', 'r') as file:\n",
        "  for line in file:\n",
        "    line = line.rstrip() # remove trailing whitespace\n",
        "    byu_words.append(line) \n",
        "\n",
        "# Sanity check:\n",
        "print(f'There are {len(byu_words)} unique types in the byu corpora. The first five are:\\n {byu_words[0:4]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 114097 unique types in the byu corpora. The first five are:\n",
            " ['word', 'the', 'and', 'of']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr4GcIhr4z0Y"
      },
      "source": [
        "# Combine into single wordlist\n",
        "words = set(nltk.corpus.brown.words() + nltk.corpus.reuters.words() + nltk.corpus.gutenberg.words() + byu_words)\n",
        "words = list(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvE2nfWfVD3z"
      },
      "source": [
        "# If you need it, write the English words to a .txt file\n",
        "\n",
        "#with open('/content/gdrive/My Drive/waves_of_words/english_list.txt', 'wt') as file:\n",
        "#  for word in words:\n",
        "#    file.write('%s\\n' % word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKJ5r2ZEfXbV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "392db33a-4954-4890-dee6-c6a779667028"
      },
      "source": [
        "# Put into compatible DataFrame\n",
        "english_data = pd.DataFrame({'lang':['english' for _ in words], 'word':words}, columns = ['lang','word'])\n",
        "\n",
        "# Apply the same preprocessing routine:\n",
        "english_data = clean_text(english_data)\n",
        "\n",
        "# Sanity check\n",
        "print(f'After preprocessing, there are {len(english_data)} training examples in english_data.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After preprocessing, there are 181375 training examples in english_data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eevxmnHW1Zen"
      },
      "source": [
        "## 1.3 Combine corpora and tokenise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5kf__yFSYb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "c0b0bc83-c9a0-463a-cafa-5e978357dfc9"
      },
      "source": [
        "# Concatenate the data frames\n",
        "data = pd.concat([chirila_df[['lang','word']], english_data], ignore_index = True)\n",
        "\n",
        "# Add a y column\n",
        "data['y'] = (data.lang != 'english').astype('float') # 1 = Indigenous word, 0 = English\n",
        "\n",
        "# Sanitiy check\n",
        "print(f'There are {len(chirila_df)} rows in `chirila_df` and {len(english_data)} in `english_data`.')\n",
        "print(f'There are {data.y.sum().astype(np.int32)} Aboriginal words and {(1 - data.y.values).sum().astype(np.int32)} English words in `data`.')\n",
        "print(f'The number of rows in `data` is {len(data)}')\n",
        "\n",
        "# Add start and end characters\n",
        "data['word'] = data['word'].apply(lambda x: 'S' + x + 'E')\n",
        "\n",
        "print('Ten random rows from `data`:')\n",
        "data.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 191091 rows in `chirila_df` and 181375 in `english_data`.\n",
            "There are 191091 Aboriginal words and 181375 English words in `data`.\n",
            "The number of rows in `data` is 372466\n",
            "Ten random rows from `data`:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lang</th>\n",
              "      <th>word</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>225492</th>\n",
              "      <td>english</td>\n",
              "      <td>SleanjawedE</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212029</th>\n",
              "      <td>english</td>\n",
              "      <td>SemmalineE</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>315902</th>\n",
              "      <td>english</td>\n",
              "      <td>SyeeE</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199279</th>\n",
              "      <td>english</td>\n",
              "      <td>SmajkerzieE</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>369963</th>\n",
              "      <td>english</td>\n",
              "      <td>SskycarvingE</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98242</th>\n",
              "      <td>Narungga</td>\n",
              "      <td>SngaruE</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>367965</th>\n",
              "      <td>english</td>\n",
              "      <td>ScastillaE</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208438</th>\n",
              "      <td>english</td>\n",
              "      <td>SlookedE</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284414</th>\n",
              "      <td>english</td>\n",
              "      <td>SfoodE</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94748</th>\n",
              "      <td>Mithaka</td>\n",
              "      <td>SkirkindariE</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            lang          word    y\n",
              "225492   english   SleanjawedE  0.0\n",
              "212029   english    SemmalineE  0.0\n",
              "315902   english         SyeeE  0.0\n",
              "199279   english   SmajkerzieE  0.0\n",
              "369963   english  SskycarvingE  0.0\n",
              "98242   Narungga       SngaruE  1.0\n",
              "367965   english    ScastillaE  0.0\n",
              "208438   english      SlookedE  0.0\n",
              "284414   english        SfoodE  0.0\n",
              "94748    Mithaka  SkirkindariE  1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWG_l7xQxUYA"
      },
      "source": [
        "# Format for tensorflow\n",
        "tkzr = Tokenizer(lower = False, char_level = True, oov_token = \"?\", filters = None) # out-of-vocab character represented by ?\n",
        "tkzr.fit_on_texts(data['word'])\n",
        "seq_list = tkzr.texts_to_sequences(data['word'])\n",
        "X = pad_sequences(seq_list, padding = 'pre', truncating = 'pre', maxlen = 20) # Cap the length of the sequnces at 20 characters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Up8opN_Zfmj"
      },
      "source": [
        "# Save data for later use\n",
        "with open('/content/gdrive/My Drive/waves_of_words/20190306_binary_model_data_and_tkzr.p', 'wb') as f:\n",
        "  p.dump((data, tkzr), f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCguduw6L6ND"
      },
      "source": [
        "# If revisiting this notebook, import the data:\n",
        "with open('/content/gdrive/My Drive/waves_of_words/20190306_binary_model_data_and_tkzr.p', 'rb') as f:\n",
        "  data, tkzr = p.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8bv6ScN_cVz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "16907700-52d5-4a99-8f8a-75ce3429a774"
      },
      "source": [
        "# Get dimensions\n",
        "# Convert data to one-hot encoding\n",
        "\n",
        "# Make sure that you're working with the right X\n",
        "assert len(X.shape) == 2\n",
        "\n",
        "print(f'Data dimensions before one-hot-encoding: {X.shape}')\n",
        "X = tf.keras.utils.to_categorical(X, dtype = 'float32') # For some reason Tensorflow requires a float input\n",
        "print(f'Data dimensions after one-hot-encoding: {X.shape}')\n",
        "X = X[:,:,1:] # Drop padding (we don't want the LSTM to learn a feature for an empty timestep)\n",
        "print(f'Data dimensions after dropping padding feature: {X.shape}')\n",
        "m, t, n = X.shape\n",
        "\n",
        "# Shuffle and split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, data['y'], test_size = 0.1, random_state = random_seed, stratify = data['y'])\n",
        "\n",
        "# Sanity check\n",
        "print(f'The shape of X_train is {X_train.shape}')\n",
        "print(f'The shape of X_test is {X_test.shape}')\n",
        "print(f'The shape of y_train is {y_train.shape}')\n",
        "print(f'The shape of y_test is {y_test.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data dimensions before one-hot-encoding: (372466, 20)\n",
            "Data dimensions after one-hot-encoding: (372466, 20, 30)\n",
            "Data dimensions after dropping padding feature: (372466, 20, 29)\n",
            "The shape of X_train is (335219, 20, 29)\n",
            "The shape of X_test is (37247, 20, 29)\n",
            "The shape of y_train is (335219,)\n",
            "The shape of y_test is (37247,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lK4gsIu8awu"
      },
      "source": [
        "# 2. Instantiate and train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWE-bvtH8aSK"
      },
      "source": [
        "def init_lstm(max_time, num_features, hidden_state_dim = 10, rnn_layers = 3, drop_rate = 0.5):\n",
        "  \"\"\"\n",
        "  Deep bidirectional LSTM for binary classification problem.\n",
        "  \n",
        "  params:\n",
        "    max_time (int): the maximum sequence length in the training data\n",
        "    num_features (int): the number of individual characters in the training set\n",
        "    lstm_hidden (int): the size of the hidden state in the LSTM cells\n",
        "    num_rnn_layers (int): the number of LSTM layers desired\n",
        "    drop_rate (float: 0 < x =< 1): the number of inputs to randomly ignore in the Dropout layers\n",
        "  \n",
        "  returns:\n",
        "    lstm_net: a Keras Model() object\n",
        "  \"\"\"\n",
        "  \n",
        "  # Define input to model\n",
        "  # NB: Althought an integer input might seem to make sense for one-hot encoding, tf requires a float input\n",
        "  seq_in = Input(shape = (max_time, num_features), dtype = 'float32', name = \"seq_in\")\n",
        "  \n",
        "  # Hidden forward layers\n",
        "  for i in range(rnn_layers):\n",
        "    if i == 0: # first layer\n",
        "      X_forw = CuDNNLSTM(units = hidden_state_dim, return_sequences = True, name = \"lstm_forward_\" + str(i))(seq_in)\n",
        "    elif i == (rnn_layers - 1): # final layer\n",
        "      X_forw = CuDNNLSTM(units = hidden_state_dim, return_sequences = False, name = \"lstm_forward_\" + str(i))(X_forw)\n",
        "    else: # all the others\n",
        "      X_forw = CuDNNLSTM(units = hidden_state_dim, return_sequences = True, name = \"lstm_forward_\" + str(i))(X_forw)\n",
        "    X_forw = Dropout(rate = drop_rate, name = \"dropout_forward_\" + str(i))(X_forw)\n",
        "  \n",
        "  # Hidden backward layers\n",
        "  for i in range(rnn_layers):\n",
        "    if i == 0: # first layer\n",
        "      X_back = CuDNNLSTM(units = hidden_state_dim, return_sequences = True, go_backwards = True, name = \"lstm_backward_\" + str(i))(seq_in)\n",
        "    elif i == (rnn_layers - 1): # final layer\n",
        "      X_back = CuDNNLSTM(units = hidden_state_dim, return_sequences = False, go_backwards = True, name = \"lstm_backward_\" + str(i))(X_back)\n",
        "    else: # all the others\n",
        "      X_back = CuDNNLSTM(units = hidden_state_dim, return_sequences = True, go_backwards = True, name = \"lstm_backward_\" + str(i))(X_back)\n",
        "    X_back = Dropout(rate = drop_rate, name = \"dropout_backward_\" + str(i))(X_back)\n",
        "\n",
        "  # Concatenate the hidden states\n",
        "  X = Concatenate()([X_forw, X_back])\n",
        "  \n",
        "  # Activation layer (apply once to each word)\n",
        "  Yhat = Dense(1, activation = \"sigmoid\")(X)\n",
        "  \n",
        "  # Create model\n",
        "  lstm_net = Model(inputs = [seq_in], outputs = Yhat)\n",
        "  \n",
        "  return lstm_net"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZdm_SzVMEEJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "outputId": "9eb7285d-666c-4e97-e587-d176545e171b"
      },
      "source": [
        "# Set hyperparameters\n",
        "hd = 100\n",
        "l = 4\n",
        "dr = 0.3\n",
        "\n",
        "# Initialise model\n",
        "model = init_lstm(max_time = t, num_features = n, hidden_state_dim = hd, rnn_layers = l, drop_rate = dr)\n",
        "\n",
        "# Sanity check\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "seq_in (InputLayer)             (None, 20, 29)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_forward_0 (CuDNNLSTM)      (None, 20, 100)      52400       seq_in[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_backward_0 (CuDNNLSTM)     (None, 20, 100)      52400       seq_in[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_forward_0 (Dropout)     (None, 20, 100)      0           lstm_forward_0[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_backward_0 (Dropout)    (None, 20, 100)      0           lstm_backward_0[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_forward_1 (CuDNNLSTM)      (None, 20, 100)      80800       dropout_forward_0[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "lstm_backward_1 (CuDNNLSTM)     (None, 20, 100)      80800       dropout_backward_0[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_forward_1 (Dropout)     (None, 20, 100)      0           lstm_forward_1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_backward_1 (Dropout)    (None, 20, 100)      0           lstm_backward_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_forward_2 (CuDNNLSTM)      (None, 20, 100)      80800       dropout_forward_1[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "lstm_backward_2 (CuDNNLSTM)     (None, 20, 100)      80800       dropout_backward_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_forward_2 (Dropout)     (None, 20, 100)      0           lstm_forward_2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_backward_2 (Dropout)    (None, 20, 100)      0           lstm_backward_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_forward_3 (CuDNNLSTM)      (None, 100)          80800       dropout_forward_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "lstm_backward_3 (CuDNNLSTM)     (None, 100)          80800       dropout_backward_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_forward_3 (Dropout)     (None, 100)          0           lstm_forward_3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_backward_3 (Dropout)    (None, 100)          0           lstm_backward_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 200)          0           dropout_forward_3[0][0]          \n",
            "                                                                 dropout_backward_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1)            201         concatenate[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 589,801\n",
            "Trainable params: 589,801\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QssTLmt-Ej4k"
      },
      "source": [
        "# Create optimizer and compile\n",
        "opt = tf.keras.optimizers.Adam(clipnorm = 5)\n",
        "model.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = [prec,rec])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxpt8BUVHxps",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        },
        "outputId": "beba0138-ddd5-46d1-f77b-413a4155101f"
      },
      "source": [
        "# Train new model using class weights and save\n",
        "hist = model.fit(x = X_train, y = y_train,\n",
        "          batch_size = 512, epochs = 28,\n",
        "          validation_data = [X_test, y_test],\n",
        "          verbose = 2)\n",
        "\n",
        "\n",
        "model.save('/content/gdrive/My Drive/waves_of_words/20190307_binary_model_30_epochs.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 335219 samples, validate on 37247 samples\n",
            "Epoch 1/28\n",
            " - 66s - loss: 0.1538 - prec: 0.9337 - rec: 0.9459 - val_loss: 0.1496 - val_prec: 0.9296 - val_rec: 0.9544\n",
            "Epoch 2/28\n",
            " - 65s - loss: 0.1461 - prec: 0.9373 - rec: 0.9490 - val_loss: 0.1454 - val_prec: 0.9426 - val_rec: 0.9425\n",
            "Epoch 3/28\n",
            " - 66s - loss: 0.1404 - prec: 0.9405 - rec: 0.9513 - val_loss: 0.1395 - val_prec: 0.9464 - val_rec: 0.9413\n",
            "Epoch 4/28\n",
            " - 66s - loss: 0.1360 - prec: 0.9423 - rec: 0.9531 - val_loss: 0.1382 - val_prec: 0.9334 - val_rec: 0.9597\n",
            "Epoch 5/28\n",
            " - 66s - loss: 0.1327 - prec: 0.9434 - rec: 0.9542 - val_loss: 0.1337 - val_prec: 0.9348 - val_rec: 0.9616\n",
            "Epoch 6/28\n",
            " - 66s - loss: 0.1296 - prec: 0.9452 - rec: 0.9557 - val_loss: 0.1324 - val_prec: 0.9411 - val_rec: 0.9560\n",
            "Epoch 7/28\n",
            " - 65s - loss: 0.1265 - prec: 0.9464 - rec: 0.9568 - val_loss: 0.1327 - val_prec: 0.9519 - val_rec: 0.9453\n",
            "Epoch 8/28\n",
            " - 65s - loss: 0.1238 - prec: 0.9480 - rec: 0.9576 - val_loss: 0.1283 - val_prec: 0.9412 - val_rec: 0.9608\n",
            "Epoch 9/28\n",
            " - 66s - loss: 0.1212 - prec: 0.9490 - rec: 0.9586 - val_loss: 0.1277 - val_prec: 0.9526 - val_rec: 0.9486\n",
            "Epoch 10/28\n",
            " - 66s - loss: 0.1187 - prec: 0.9502 - rec: 0.9594 - val_loss: 0.1287 - val_prec: 0.9551 - val_rec: 0.9426\n",
            "Epoch 11/28\n",
            " - 66s - loss: 0.1168 - prec: 0.9510 - rec: 0.9600 - val_loss: 0.1250 - val_prec: 0.9476 - val_rec: 0.9573\n",
            "Epoch 12/28\n",
            " - 66s - loss: 0.1148 - prec: 0.9519 - rec: 0.9611 - val_loss: 0.1251 - val_prec: 0.9459 - val_rec: 0.9570\n",
            "Epoch 13/28\n",
            " - 66s - loss: 0.1127 - prec: 0.9526 - rec: 0.9616 - val_loss: 0.1217 - val_prec: 0.9520 - val_rec: 0.9533\n",
            "Epoch 14/28\n",
            " - 66s - loss: 0.1110 - prec: 0.9533 - rec: 0.9621 - val_loss: 0.1214 - val_prec: 0.9548 - val_rec: 0.9494\n",
            "Epoch 15/28\n",
            " - 66s - loss: 0.1088 - prec: 0.9541 - rec: 0.9633 - val_loss: 0.1252 - val_prec: 0.9373 - val_rec: 0.9679\n",
            "Epoch 16/28\n",
            " - 66s - loss: 0.1068 - prec: 0.9553 - rec: 0.9638 - val_loss: 0.1210 - val_prec: 0.9463 - val_rec: 0.9614\n",
            "Epoch 17/28\n",
            " - 66s - loss: 0.1047 - prec: 0.9560 - rec: 0.9647 - val_loss: 0.1208 - val_prec: 0.9436 - val_rec: 0.9662\n",
            "Epoch 18/28\n",
            " - 66s - loss: 0.1029 - prec: 0.9571 - rec: 0.9657 - val_loss: 0.1193 - val_prec: 0.9515 - val_rec: 0.9575\n",
            "Epoch 19/28\n",
            " - 66s - loss: 0.1008 - prec: 0.9575 - rec: 0.9661 - val_loss: 0.1182 - val_prec: 0.9509 - val_rec: 0.9586\n",
            "Epoch 20/28\n",
            " - 66s - loss: 0.0992 - prec: 0.9582 - rec: 0.9672 - val_loss: 0.1190 - val_prec: 0.9530 - val_rec: 0.9541\n",
            "Epoch 21/28\n",
            " - 66s - loss: 0.0972 - prec: 0.9590 - rec: 0.9678 - val_loss: 0.1222 - val_prec: 0.9497 - val_rec: 0.9600\n",
            "Epoch 22/28\n",
            " - 66s - loss: 0.0953 - prec: 0.9603 - rec: 0.9684 - val_loss: 0.1199 - val_prec: 0.9499 - val_rec: 0.9610\n",
            "Epoch 23/28\n",
            " - 66s - loss: 0.0942 - prec: 0.9599 - rec: 0.9689 - val_loss: 0.1203 - val_prec: 0.9517 - val_rec: 0.9590\n",
            "Epoch 24/28\n",
            " - 66s - loss: 0.0921 - prec: 0.9613 - rec: 0.9695 - val_loss: 0.1198 - val_prec: 0.9548 - val_rec: 0.9564\n",
            "Epoch 25/28\n",
            " - 66s - loss: 0.0904 - prec: 0.9621 - rec: 0.9704 - val_loss: 0.1185 - val_prec: 0.9504 - val_rec: 0.9620\n",
            "Epoch 26/28\n",
            " - 66s - loss: 0.0889 - prec: 0.9627 - rec: 0.9710 - val_loss: 0.1200 - val_prec: 0.9526 - val_rec: 0.9597\n",
            "Epoch 27/28\n",
            " - 66s - loss: 0.0870 - prec: 0.9635 - rec: 0.9713 - val_loss: 0.1235 - val_prec: 0.9518 - val_rec: 0.9592\n",
            "Epoch 28/28\n",
            " - 66s - loss: 0.0857 - prec: 0.9639 - rec: 0.9722 - val_loss: 0.1217 - val_prec: 0.9547 - val_rec: 0.9564\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmQo49k39aRs"
      },
      "source": [
        "# 3. Evaluate the model\n",
        "\n",
        "Have a look at how it's going on the training and test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nplBqtLbfby-"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.style.use('dark_background')\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2czEkXGfgyA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "d0f9c6c9-211c-40a8-e910-c5935e4351e6"
      },
      "source": [
        "epochs = [x + 3 for x,y in enumerate(hist.history['loss'])] # generate sequences of x-values\n",
        "f, (lplt, pplt, rplt) = plt.subplots(1, 3, figsize = (18,5), sharex = True)\n",
        "\n",
        "lplt.plot(epochs, hist.history['loss'], color = 'g')\n",
        "lplt.plot(epochs, hist.history['val_loss'], color = 'b')\n",
        "lplt.set_ylim([0., 0.2])\n",
        "\n",
        "pplt.plot(epochs, hist.history['prec'], color = 'g')\n",
        "pplt.plot(epochs, hist.history['val_prec'], color = 'b')\n",
        "pplt.set_ylim([0.8, 1.])\n",
        "\n",
        "rplt.plot(epochs, hist.history['rec'], color = 'g')\n",
        "rplt.plot(epochs, hist.history['val_rec'], color = 'b')\n",
        "rplt.set_ylim([0.8, 1.])\n",
        "\n",
        "f.suptitle('Loss, Precision and Recall on the Training and Test sets (30 epochs)')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABBsAAAFTCAYAAAB4cQRiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1296x360 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ldqmn5B8KKoK"
      },
      "source": [
        "# 4. Try on some Trove data\n",
        "\n",
        "Now we've trained the model, how terribly does it do on actual Trove data?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAGVusCLKUTQ"
      },
      "source": [
        "# Load sample articles\n",
        "with open('/content/gdrive/My Drive/waves_of_words/one_thousand_articles.p', 'rb') as file:\n",
        "  one_thousand_articles = p.load(file)\n",
        "\n",
        "# Load tokeniser (no need to load the data)\n",
        "with open('/content/gdrive/My Drive/waves_of_words/20190306_binary_model_data_and_tkzr.p', 'rb') as f:\n",
        "  _, tkzr = p.load(f)\n",
        "\n",
        "# Load the model\n",
        "model = load_model('/content/gdrive/My Drive/waves_of_words/20190307_binary_model_30_epochs.h5', custom_objects = {'prec':prec, 'rec':rec})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN5K9o33KeMA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0cdd9498-0115-494a-8fc0-00a1d7feff17"
      },
      "source": [
        "# Preprocess text:\n",
        "samp_df = pd.DataFrame(data = one_thousand_articles, columns = ['id', 'art_id', 'tokens'])\n",
        "\n",
        "# Unnest the list column\n",
        "unnested = samp_df.set_index(['id', 'art_id'])['tokens'].apply(pd.Series).stack().reset_index()\n",
        "unnested.columns = ['id', 'art_id', 'tkn_idx', 'token']\n",
        "\n",
        "# Drop duplicates\n",
        "unnested.drop_duplicates(subset = 'token', inplace = True)\n",
        "\n",
        "# Preprocess tokens\n",
        "unnested.loc[:,'token'] = (unnested['token']\n",
        "                  .str.replace(r'&.{1,7};', '') # Strip out html entities\n",
        "                  .str.replace(r'\\\\N', '') # Strip out missing values written as '\\N'\n",
        "                  .str.replace(r'\\(.+\\)', '') # Strip out parenthetical comments\n",
        "                  .str.normalize('NFKD') # Strip out accents\n",
        "                  .str.encode('ascii', errors='ignore')\n",
        "                  .str.decode('utf-8') \n",
        "                  .str.replace(r'\\d|\\W|_', '') # Strip out all non-word characters and underscores\n",
        "                  .str.lower() # To lower case\n",
        "                 )\n",
        "\n",
        "# Add start and end symbols\n",
        "unnested['token'] = unnested['token'].apply(lambda x: 'S' + x + 'E')\n",
        "\n",
        "# Apply tokensier\n",
        "seq_list = tkzr.texts_to_sequences(unnested['token'])\n",
        "maxlen = 20\n",
        "X = pad_sequences(seq_list, padding = 'pre', truncating = 'pre', maxlen = maxlen)\n",
        "\n",
        "# One-hot encode\n",
        "X = tf.keras.utils.to_categorical(X, dtype = 'float32')\n",
        "\n",
        "# Remove padding slice\n",
        "X = X[:,:,1:]\n",
        "\n",
        "# Sanity check\n",
        "print(f'There are {len(unnested)} tokens in the `unnested` data frame.')\n",
        "print(f'Sequences are capped at {maxlen} characters.')\n",
        "print(f'There are {len(tkzr.word_index)} characters in the tokenizer\\'s vocabulary')\n",
        "print(f'`X` has dimensions {X.shape[0]}, {X.shape[1]} and {X.shape[2]}.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 106409 tokens in the `unnested` data frame.\n",
            "Sequences are capped at 20 characters.\n",
            "There are 29 characters in the tokenizer's vocabulary\n",
            "`X` has dimensions 106409, 20 and 29.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_1kXE_iXuID"
      },
      "source": [
        "# Predict which of the tokens are aboriginal words.\n",
        "unnested['y_hat'] = model.predict(X) # Get probabilities\n",
        "unnested['class'] = unnested.y_hat >= 0.5 # Classify"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuz1kEuMbFzk"
      },
      "source": [
        "# Which articles have the greatest number of 'aboriginal' words?\n",
        "aboriginal_words_per_article = (unnested[['art_id','class']]\n",
        "                                .groupby('art_id') # consider each article\n",
        "                                .sum() # Sum the number of aboriginal words (english = 0)\n",
        "                                .reset_index()\n",
        "                                .sort_values('class', ascending = False)\n",
        "                               )\n",
        "aboriginal_words_per_article['url'] = (aboriginal_words_per_article['art_id']\n",
        "                                       .apply(lambda x: \"https://trove.nla.gov.au/newspaper/article/\" + str(x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqRXZ_f1cM7S"
      },
      "source": [
        "# Have a look at some of them\n",
        "from functools import partial\n",
        "\n",
        "def inspect_general(idx, df_one, df_two):\n",
        "  # Print the url\n",
        "  print(df_one['url'].iloc[idx])\n",
        "  \n",
        "  # Get data for particular article\n",
        "  article = df_one['art_id'].iloc[idx]\n",
        "  article_data = df_two[df_two['art_id'] == article]\n",
        "  \n",
        "  # List the predicted aboriginal words\n",
        "  ab_wrds = article_data[article_data['class'] == True]\n",
        "  print(f'Of {len(article_data)} examined words, {len(ab_wrds)} were found to be aboriginal.')\n",
        "  print(f'Supposed aboriginal words:')\n",
        "  display(ab_wrds.sort_values('y_hat', ascending = False))\n",
        "  \n",
        "  return None\n",
        "  \n",
        "inspect_article = partial(inspect_general, df_one = aboriginal_words_per_article, df_two = unnested)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeRU2IXjfUsL"
      },
      "source": [
        "# Another way of filtering the results: which articles have the highest proportion of words with\n",
        "# scores over a certain threshold?\n",
        "def compute_prop(df, threshold = 0.8):\n",
        "  \n",
        "  num_over = len(df[df['y_hat'] > threshold])\n",
        "  num_rows = len(df)\n",
        "  \n",
        "  prop = num_over / num_rows\n",
        "  \n",
        "  out = pd.DataFrame.from_dict({'prop' : [prop], 'words_examined' : [num_rows]})\n",
        "  \n",
        "  return out\n",
        "\n",
        "highest_prop = (unnested[['art_id','y_hat']]\n",
        "                .groupby('art_id') # consider each article\n",
        "                .apply(compute_prop) # Get the proportion\n",
        "                .sort_values('prop', ascending = False)\n",
        "                .reset_index()\n",
        "               )\n",
        "highest_prop['url'] = highest_prop['art_id'].apply(lambda x: \"https://trove.nla.gov.au/newspaper/article/\" + str(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnhW058DoiiT"
      },
      "source": [
        "def inspect_two(idx, df_one, df_two):\n",
        "  \n",
        "  # Print the url\n",
        "  print(df_one['url'].iloc[idx])\n",
        "  \n",
        "  # Get data for particular article\n",
        "  article = df_one['art_id'].iloc[idx]\n",
        "  article_data = df_two[df_two['art_id'] == article]\n",
        "  \n",
        "  # List the predicted aboriginal words\n",
        "  ab_wrds = article_data[article_data['y_hat'] > 0.8]\n",
        "  print(f'Of {len(article_data)} examined words, {len(ab_wrds)} had a greater probability than 0.8.')\n",
        "  print(f'Supposed aboriginal words:')\n",
        "  display(ab_wrds.sort_values('y_hat', ascending = False))\n",
        "  \n",
        "  return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8Wg2zvFrDwC"
      },
      "source": [
        "highest_prop_fil = highest_prop[highest_prop['words_examined'] > 100]\n",
        "insp_prop_dat = partial(inspect_two, df_one = highest_prop_fil, df_two = unnested)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRNzY61bv_b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1340
        },
        "outputId": "0fd1dd63-d9e3-4bfe-df70-655c5c8a8696"
      },
      "source": [
        "insp_prop_dat(6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://trove.nla.gov.au/newspaper/article/18587021\n",
            "Of 267 examined words, 40 had a greater probability than 0.8.\n",
            "Supposed aboriginal words:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>art_id</th>\n",
              "      <th>tkn_idx</th>\n",
              "      <th>token</th>\n",
              "      <th>y_hat</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>49812</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>261</td>\n",
              "      <td>SooaatrucE</td>\n",
              "      <td>0.999987</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49666</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>115</td>\n",
              "      <td>SpupuliE</td>\n",
              "      <td>0.999940</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49704</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>153</td>\n",
              "      <td>SltiljijE</td>\n",
              "      <td>0.998638</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49675</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>124</td>\n",
              "      <td>StharuE</td>\n",
              "      <td>0.998021</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49711</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>160</td>\n",
              "      <td>SkiiiwayE</td>\n",
              "      <td>0.996767</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49741</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>190</td>\n",
              "      <td>SpoaaliE</td>\n",
              "      <td>0.992320</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49756</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>205</td>\n",
              "      <td>SuuvernmrctE</td>\n",
              "      <td>0.990817</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49594</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>43</td>\n",
              "      <td>SuiembenE</td>\n",
              "      <td>0.986694</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49692</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>141</td>\n",
              "      <td>SnuiketaE</td>\n",
              "      <td>0.983120</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49730</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>179</td>\n",
              "      <td>SlaruE</td>\n",
              "      <td>0.979458</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49580</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>29</td>\n",
              "      <td>SdilliE</td>\n",
              "      <td>0.978946</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49706</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>155</td>\n",
              "      <td>SrducaE</td>\n",
              "      <td>0.967815</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49702</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>151</td>\n",
              "      <td>StuctnaE</td>\n",
              "      <td>0.963406</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49681</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>130</td>\n",
              "      <td>SikuE</td>\n",
              "      <td>0.961618</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49703</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>152</td>\n",
              "      <td>SwouiilE</td>\n",
              "      <td>0.959180</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49762</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>211</td>\n",
              "      <td>SthijE</td>\n",
              "      <td>0.958744</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49697</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>146</td>\n",
              "      <td>SjamaE</td>\n",
              "      <td>0.951399</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49813</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>262</td>\n",
              "      <td>SnarroE</td>\n",
              "      <td>0.950884</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49836</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>285</td>\n",
              "      <td>SmtjaaE</td>\n",
              "      <td>0.950512</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49727</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>176</td>\n",
              "      <td>SimrtljE</td>\n",
              "      <td>0.941439</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49656</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>105</td>\n",
              "      <td>SnujajeatudE</td>\n",
              "      <td>0.938604</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49677</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>126</td>\n",
              "      <td>SturaE</td>\n",
              "      <td>0.937292</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49673</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>122</td>\n",
              "      <td>SmatirjlE</td>\n",
              "      <td>0.927669</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49737</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>186</td>\n",
              "      <td>SthciijE</td>\n",
              "      <td>0.920223</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49584</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>33</td>\n",
              "      <td>SpurtimE</td>\n",
              "      <td>0.918775</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49829</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>278</td>\n",
              "      <td>SoououjE</td>\n",
              "      <td>0.916919</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49861</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>310</td>\n",
              "      <td>StloorE</td>\n",
              "      <td>0.911140</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49771</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>220</td>\n",
              "      <td>SwimraeriE</td>\n",
              "      <td>0.899989</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49646</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>95</td>\n",
              "      <td>SiweiE</td>\n",
              "      <td>0.896830</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49845</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>294</td>\n",
              "      <td>SdillerntE</td>\n",
              "      <td>0.886994</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49641</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>90</td>\n",
              "      <td>SimportmiE</td>\n",
              "      <td>0.861392</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49894</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>343</td>\n",
              "      <td>SmororE</td>\n",
              "      <td>0.856726</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49856</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>305</td>\n",
              "      <td>SnuuldE</td>\n",
              "      <td>0.846926</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49720</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>169</td>\n",
              "      <td>SjldejE</td>\n",
              "      <td>0.846822</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49819</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>268</td>\n",
              "      <td>SgnageaE</td>\n",
              "      <td>0.846557</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49811</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>260</td>\n",
              "      <td>SlikeljE</td>\n",
              "      <td>0.838292</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49701</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>150</td>\n",
              "      <td>StaralE</td>\n",
              "      <td>0.827028</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49805</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>254</td>\n",
              "      <td>SyalloakE</td>\n",
              "      <td>0.809341</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49759</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>208</td>\n",
              "      <td>SprtnuntE</td>\n",
              "      <td>0.804980</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49626</th>\n",
              "      <td>347860</td>\n",
              "      <td>18587021</td>\n",
              "      <td>75</td>\n",
              "      <td>SraijE</td>\n",
              "      <td>0.802655</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id    art_id  tkn_idx         token     y_hat  class\n",
              "49812  347860  18587021      261    SooaatrucE  0.999987   True\n",
              "49666  347860  18587021      115      SpupuliE  0.999940   True\n",
              "49704  347860  18587021      153     SltiljijE  0.998638   True\n",
              "49675  347860  18587021      124       StharuE  0.998021   True\n",
              "49711  347860  18587021      160     SkiiiwayE  0.996767   True\n",
              "49741  347860  18587021      190      SpoaaliE  0.992320   True\n",
              "49756  347860  18587021      205  SuuvernmrctE  0.990817   True\n",
              "49594  347860  18587021       43     SuiembenE  0.986694   True\n",
              "49692  347860  18587021      141     SnuiketaE  0.983120   True\n",
              "49730  347860  18587021      179        SlaruE  0.979458   True\n",
              "49580  347860  18587021       29       SdilliE  0.978946   True\n",
              "49706  347860  18587021      155       SrducaE  0.967815   True\n",
              "49702  347860  18587021      151      StuctnaE  0.963406   True\n",
              "49681  347860  18587021      130         SikuE  0.961618   True\n",
              "49703  347860  18587021      152      SwouiilE  0.959180   True\n",
              "49762  347860  18587021      211        SthijE  0.958744   True\n",
              "49697  347860  18587021      146        SjamaE  0.951399   True\n",
              "49813  347860  18587021      262       SnarroE  0.950884   True\n",
              "49836  347860  18587021      285       SmtjaaE  0.950512   True\n",
              "49727  347860  18587021      176      SimrtljE  0.941439   True\n",
              "49656  347860  18587021      105  SnujajeatudE  0.938604   True\n",
              "49677  347860  18587021      126        SturaE  0.937292   True\n",
              "49673  347860  18587021      122     SmatirjlE  0.927669   True\n",
              "49737  347860  18587021      186      SthciijE  0.920223   True\n",
              "49584  347860  18587021       33      SpurtimE  0.918775   True\n",
              "49829  347860  18587021      278      SoououjE  0.916919   True\n",
              "49861  347860  18587021      310       StloorE  0.911140   True\n",
              "49771  347860  18587021      220    SwimraeriE  0.899989   True\n",
              "49646  347860  18587021       95        SiweiE  0.896830   True\n",
              "49845  347860  18587021      294    SdillerntE  0.886994   True\n",
              "49641  347860  18587021       90    SimportmiE  0.861392   True\n",
              "49894  347860  18587021      343       SmororE  0.856726   True\n",
              "49856  347860  18587021      305       SnuuldE  0.846926   True\n",
              "49720  347860  18587021      169       SjldejE  0.846822   True\n",
              "49819  347860  18587021      268      SgnageaE  0.846557   True\n",
              "49811  347860  18587021      260      SlikeljE  0.838292   True\n",
              "49701  347860  18587021      150       StaralE  0.827028   True\n",
              "49805  347860  18587021      254     SyalloakE  0.809341   True\n",
              "49759  347860  18587021      208     SprtnuntE  0.804980   True\n",
              "49626  347860  18587021       75        SraijE  0.802655   True"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4jvbJY4meIO"
      },
      "source": [
        "After a first look at the results, a few thoughts:\n",
        "\n",
        "- The model definitely struggles with messy OCR. Exposing it to messy OCR would be one solution. Cleaning up the training data somehow would be another.\n",
        "- If you look simply for articles that have the most positives you get a lot of advertisments. Advertisements can probably simply be excluded from the search, using the 'category' column in the WoW database.\n",
        "- There are a lot of place names. Perhaps known place names could be added to the stopwords list, by harvesting them from geonames, for example?\n",
        "- Lots of the articles contain duplicate aboriginal words, e.g. a short story whose characters have aboriginal names, or a news story that refers repeatedly to the same place. So it is a good idea to keep only unique tokens for each article before running the model."
      ]
    }
  ]
}